{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nishi\\AppData\\Local\\Temp\\ipykernel_2348\\1319228764.py:6: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('C:/Users/nishi/Documents/data science/SDP/clean_dataset.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/9/2010</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>Chris Columbus returns to his comfort zone for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358249</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>PopcornQ</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8/14/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358250</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>ColeSmithey.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11/1/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358251</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>Fantastica Daily</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11/2/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358252</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>Mountain Xpress (Asheville, NC)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3/7/2007</td>\n",
       "      <td>Seen today, it's not only a startling indictme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358253</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>Sarasota Herald-Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/28/2011</td>\n",
       "      <td>A simple two-act story: Prelude to war, and th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358254 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotten_tomatoes_link  top_critic                   publisher_name  \\\n",
       "0                 m/0814255       False          Sunday Mail (Australia)   \n",
       "1                 m/0814255        True                 Arizona Republic   \n",
       "2                 m/0814255        True              The Age (Australia)   \n",
       "3                 m/0814255       False                Daily Mirror (UK)   \n",
       "4                 m/0814255        True                         Time Out   \n",
       "...                     ...         ...                              ...   \n",
       "358249          m/zulu_dawn       False                         PopcornQ   \n",
       "358250          m/zulu_dawn       False                  ColeSmithey.com   \n",
       "358251          m/zulu_dawn       False                 Fantastica Daily   \n",
       "358252          m/zulu_dawn       False  Mountain Xpress (Asheville, NC)   \n",
       "358253          m/zulu_dawn       False          Sarasota Herald-Tribune   \n",
       "\n",
       "       review_type review_score review_date  \\\n",
       "0            Fresh          3.5    2/9/2010   \n",
       "1            Fresh          3.5   2/10/2010   \n",
       "2            Fresh            3   2/10/2010   \n",
       "3            Fresh            4   2/10/2010   \n",
       "4           Rotten            2   2/10/2010   \n",
       "...            ...          ...         ...   \n",
       "358249       Fresh          3.0   8/14/2005   \n",
       "358250       Fresh          4.0   11/1/2005   \n",
       "358251      Rotten          2.0   11/2/2005   \n",
       "358252       Fresh          3.5    3/7/2007   \n",
       "358253      Rotten          3.5   2/28/2011   \n",
       "\n",
       "                                           review_content  \n",
       "0       Whether audiences will get behind The Lightnin...  \n",
       "1       Percy Jackson isn't a great movie, but it's a ...  \n",
       "2       Crammed with dragons, set-destroying fights an...  \n",
       "3       This action-packed fantasy adventure, based on...  \n",
       "4       Chris Columbus returns to his comfort zone for...  \n",
       "...                                                   ...  \n",
       "358249                                                NaN  \n",
       "358250                                                NaN  \n",
       "358251                                                NaN  \n",
       "358252  Seen today, it's not only a startling indictme...  \n",
       "358253  A simple two-act story: Prelude to war, and th...  \n",
       "\n",
       "[358254 rows x 7 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#path = os.path('C:/Users/nishi/Documents/data science/SDP')\n",
    "#data = pd.read_csv(path)\n",
    "\n",
    "df = pd.read_csv('C:/Users/nishi/Documents/data science/SDP/clean_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Sunday Mail (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/9/2010</td>\n",
       "      <td>Whether audiences will get behind The Lightnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>Arizona Republic</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>Percy Jackson isn't a great movie, but it's a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>Crammed with dragons, set-destroying fights an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>This action-packed fantasy adventure, based on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>Chris Columbus returns to his comfort zone for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>CinemaBlend</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>The best thing you can say about Chris Columbu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Screen Rant</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>Percy Jackson may not be Harry Potter good, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>Although the standard allegorical bases for my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>New York Daily News</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>You don't even have to be familiar with the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>This is generic filmmaking at its most banal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>MSN Movies</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>An attempt to steal some of Harry Potter's thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>School Library Journal</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>Columbus aims at nothing more than providing a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Filmcritic.com</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>3</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>gets so many things right that when it goes as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Metromix.com</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>The disappearance of lightning simply is not i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Shadows on the Wall</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>The Greek-gods premise lets the filmmakers ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>ViewLondon</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>Enjoyable, nicely paced family adventure with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>TheDivaReview.com</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2/12/2010</td>\n",
       "      <td>The Lightning Thief is all crass ineptitude an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>MTV</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>1</td>\n",
       "      <td>2/12/2010</td>\n",
       "      <td>Sadly worthy of its dumping into the cinematic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Boxoffice Magazine</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2/12/2010</td>\n",
       "      <td>Columbus knows his way around this kind of mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Common Sense Media</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2</td>\n",
       "      <td>2/12/2010</td>\n",
       "      <td>Too scary for younger fans of the popular book.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rotten_tomatoes_link  top_critic           publisher_name review_type  \\\n",
       "0             m/0814255       False  Sunday Mail (Australia)       Fresh   \n",
       "1             m/0814255        True         Arizona Republic       Fresh   \n",
       "2             m/0814255        True      The Age (Australia)       Fresh   \n",
       "3             m/0814255       False        Daily Mirror (UK)       Fresh   \n",
       "4             m/0814255        True                 Time Out      Rotten   \n",
       "5             m/0814255       False              CinemaBlend       Fresh   \n",
       "6             m/0814255       False              Screen Rant       Fresh   \n",
       "7             m/0814255        True           New York Times      Rotten   \n",
       "8             m/0814255        True      New York Daily News       Fresh   \n",
       "9             m/0814255        True        Los Angeles Times      Rotten   \n",
       "10            m/0814255        True               MSN Movies       Fresh   \n",
       "11            m/0814255       False   School Library Journal       Fresh   \n",
       "12            m/0814255       False           Filmcritic.com      Rotten   \n",
       "13            m/0814255       False             Metromix.com      Rotten   \n",
       "14            m/0814255       False      Shadows on the Wall       Fresh   \n",
       "15            m/0814255       False               ViewLondon       Fresh   \n",
       "16            m/0814255       False        TheDivaReview.com      Rotten   \n",
       "17            m/0814255       False                      MTV      Rotten   \n",
       "18            m/0814255       False       Boxoffice Magazine      Rotten   \n",
       "19            m/0814255       False       Common Sense Media      Rotten   \n",
       "\n",
       "   review_score review_date                                     review_content  \n",
       "0           3.5    2/9/2010  Whether audiences will get behind The Lightnin...  \n",
       "1           3.5   2/10/2010  Percy Jackson isn't a great movie, but it's a ...  \n",
       "2             3   2/10/2010  Crammed with dragons, set-destroying fights an...  \n",
       "3             4   2/10/2010  This action-packed fantasy adventure, based on...  \n",
       "4             2   2/10/2010  Chris Columbus returns to his comfort zone for...  \n",
       "5             3   2/11/2010  The best thing you can say about Chris Columbu...  \n",
       "6           3.5   2/11/2010  Percy Jackson may not be Harry Potter good, bu...  \n",
       "7             2   2/11/2010  Although the standard allegorical bases for my...  \n",
       "8             3   2/11/2010  You don't even have to be familiar with the fi...  \n",
       "9             2   2/11/2010  This is generic filmmaking at its most banal, ...  \n",
       "10            3   2/11/2010  An attempt to steal some of Harry Potter's thu...  \n",
       "11         2.75   2/11/2010  Columbus aims at nothing more than providing a...  \n",
       "12            3   2/11/2010  gets so many things right that when it goes as...  \n",
       "13            2   2/11/2010  The disappearance of lightning simply is not i...  \n",
       "14            3   2/11/2010  The Greek-gods premise lets the filmmakers ind...  \n",
       "15            3   2/11/2010  Enjoyable, nicely paced family adventure with ...  \n",
       "16          2.5   2/12/2010  The Lightning Thief is all crass ineptitude an...  \n",
       "17            1   2/12/2010  Sadly worthy of its dumping into the cinematic...  \n",
       "18          2.5   2/12/2010  Columbus knows his way around this kind of mat...  \n",
       "19            2   2/12/2010    Too scary for younger fans of the popular book.  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358234</th>\n",
       "      <td>m/zorba_the_greek</td>\n",
       "      <td>False</td>\n",
       "      <td>Movie Mom</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5/29/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358235</th>\n",
       "      <td>m/zorba_the_greek</td>\n",
       "      <td>False</td>\n",
       "      <td>Goatdog's Movies</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2/29/2008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358236</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Eye for Film</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6/17/1964</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358237</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>TV Guide</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1/1/2000</td>\n",
       "      <td>This amazing film is devastatingly accurate in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358238</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Cinema Signals</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7/23/2003</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358239</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Las Vegas Review-Journal</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9/10/2004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358240</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Reeling Reviews</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10/8/2004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358241</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Boulder Weekly</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11/12/2004</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358242</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>EmanuelLevy.Com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6/29/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358243</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Filmcritic.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1/31/2006</td>\n",
       "      <td>Though, there's an awful lot of lounging aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358244</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Cinema em Cena</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5/1/2009</td>\n",
       "      <td>Responsvel por lanar a carreira de Caine, o fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358245</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Radio Times</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7/10/2017</td>\n",
       "      <td>The movie is a revelation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358246</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Sky Cinema</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7/10/2017</td>\n",
       "      <td>This is that rarity in films - an all-action, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358247</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>False</td>\n",
       "      <td>Empire Magazine</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7/10/2017</td>\n",
       "      <td>As a spectacular war film with a powerful mora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358248</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>EmanuelLevy.Com</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6/25/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358249</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>PopcornQ</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8/14/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358250</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>ColeSmithey.com</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11/1/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358251</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>Fantastica Daily</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11/2/2005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358252</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>Mountain Xpress (Asheville, NC)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3/7/2007</td>\n",
       "      <td>Seen today, it's not only a startling indictme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358253</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>False</td>\n",
       "      <td>Sarasota Herald-Tribune</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2/28/2011</td>\n",
       "      <td>A simple two-act story: Prelude to war, and th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotten_tomatoes_link  top_critic                   publisher_name  \\\n",
       "358234    m/zorba_the_greek       False                        Movie Mom   \n",
       "358235    m/zorba_the_greek       False                 Goatdog's Movies   \n",
       "358236               m/zulu       False                     Eye for Film   \n",
       "358237               m/zulu       False                         TV Guide   \n",
       "358238               m/zulu       False                   Cinema Signals   \n",
       "358239               m/zulu       False         Las Vegas Review-Journal   \n",
       "358240               m/zulu       False                  Reeling Reviews   \n",
       "358241               m/zulu       False                   Boulder Weekly   \n",
       "358242               m/zulu       False                  EmanuelLevy.Com   \n",
       "358243               m/zulu       False                   Filmcritic.com   \n",
       "358244               m/zulu       False                   Cinema em Cena   \n",
       "358245               m/zulu       False                      Radio Times   \n",
       "358246               m/zulu       False                       Sky Cinema   \n",
       "358247               m/zulu       False                  Empire Magazine   \n",
       "358248          m/zulu_dawn       False                  EmanuelLevy.Com   \n",
       "358249          m/zulu_dawn       False                         PopcornQ   \n",
       "358250          m/zulu_dawn       False                  ColeSmithey.com   \n",
       "358251          m/zulu_dawn       False                 Fantastica Daily   \n",
       "358252          m/zulu_dawn       False  Mountain Xpress (Asheville, NC)   \n",
       "358253          m/zulu_dawn       False          Sarasota Herald-Tribune   \n",
       "\n",
       "       review_type review_score review_date  \\\n",
       "358234       Fresh          4.0   5/29/2005   \n",
       "358235       Fresh          4.0   2/29/2008   \n",
       "358236       Fresh          4.0   6/17/1964   \n",
       "358237       Fresh          5.0    1/1/2000   \n",
       "358238       Fresh          4.0   7/23/2003   \n",
       "358239       Fresh          4.0   9/10/2004   \n",
       "358240       Fresh          4.0   10/8/2004   \n",
       "358241       Fresh          4.0  11/12/2004   \n",
       "358242       Fresh          3.0   6/29/2005   \n",
       "358243       Fresh          3.0   1/31/2006   \n",
       "358244       Fresh          3.0    5/1/2009   \n",
       "358245       Fresh          5.0   7/10/2017   \n",
       "358246       Fresh          5.0   7/10/2017   \n",
       "358247       Fresh          4.0   7/10/2017   \n",
       "358248      Rotten          2.0   6/25/2005   \n",
       "358249       Fresh          3.0   8/14/2005   \n",
       "358250       Fresh          4.0   11/1/2005   \n",
       "358251      Rotten          2.0   11/2/2005   \n",
       "358252       Fresh          3.5    3/7/2007   \n",
       "358253      Rotten          3.5   2/28/2011   \n",
       "\n",
       "                                           review_content  \n",
       "358234                                                NaN  \n",
       "358235                                                NaN  \n",
       "358236                                                NaN  \n",
       "358237  This amazing film is devastatingly accurate in...  \n",
       "358238                                                NaN  \n",
       "358239                                                NaN  \n",
       "358240                                                NaN  \n",
       "358241                                                NaN  \n",
       "358242                                                NaN  \n",
       "358243  Though, there's an awful lot of lounging aroun...  \n",
       "358244  Responsvel por lanar a carreira de Caine, o fi...  \n",
       "358245                         The movie is a revelation.  \n",
       "358246  This is that rarity in films - an all-action, ...  \n",
       "358247  As a spectacular war film with a powerful mora...  \n",
       "358248                                                NaN  \n",
       "358249                                                NaN  \n",
       "358250                                                NaN  \n",
       "358251                                                NaN  \n",
       "358252  Seen today, it's not only a startling indictme...  \n",
       "358253  A simple two-act story: Prelude to war, and th...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358254, 7)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 358254 entries, 0 to 358253\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count   Dtype \n",
      "---  ------                --------------   ----- \n",
      " 0   rotten_tomatoes_link  358254 non-null  object\n",
      " 1   top_critic            358254 non-null  bool  \n",
      " 2   publisher_name        358254 non-null  object\n",
      " 3   review_type           358254 non-null  object\n",
      " 4   review_score          357973 non-null  object\n",
      " 5   review_date           358254 non-null  object\n",
      " 6   review_content        313713 non-null  object\n",
      "dtypes: bool(1), object(6)\n",
      "memory usage: 16.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rotten_tomatoes_link    0\n",
       "top_critic              0\n",
       "publisher_name          0\n",
       "review_type             0\n",
       "review_score            0\n",
       "review_date             0\n",
       "review_content          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROPPING ROWS HAVING NULL REVIEW CONTENT AND NULL SCORES\n",
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313432</td>\n",
       "      <td>313432</td>\n",
       "      <td>313432</td>\n",
       "      <td>313432</td>\n",
       "      <td>313432</td>\n",
       "      <td>313432</td>\n",
       "      <td>313432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>16869</td>\n",
       "      <td>2</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>189</td>\n",
       "      <td>7223</td>\n",
       "      <td>279938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m/star_wars_the_rise_of_skywalker</td>\n",
       "      <td>False</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>1/1/2000</td>\n",
       "      <td>full review at Movies for the Masses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>352</td>\n",
       "      <td>253018</td>\n",
       "      <td>7650</td>\n",
       "      <td>210372</td>\n",
       "      <td>55395</td>\n",
       "      <td>4942</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rotten_tomatoes_link top_critic  publisher_name  \\\n",
       "count                               313432     313432          313432   \n",
       "unique                               16869          2            1142   \n",
       "top      m/star_wars_the_rise_of_skywalker      False  New York Times   \n",
       "freq                                   352     253018            7650   \n",
       "\n",
       "       review_type review_score review_date  \\\n",
       "count       313432       313432      313432   \n",
       "unique           2          189        7223   \n",
       "top          Fresh            3    1/1/2000   \n",
       "freq        210372        55395        4942   \n",
       "\n",
       "                              review_content  \n",
       "count                                 313432  \n",
       "unique                                279938  \n",
       "top     full review at Movies for the Masses  \n",
       "freq                                     200  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rotten_tomatoes_link    0\n",
       "top_critic              0\n",
       "publisher_name          0\n",
       "review_type             0\n",
       "review_score            0\n",
       "review_date             0\n",
       "review_content          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['review_score']==\"4-Mar\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"4-Feb\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"B+\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"4-Apr\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"2.5/4\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"3.5/4\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"B\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"B-\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"A-\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"1.5/4\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"4-Jan\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"10-Sep\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"A\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"C-\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"10-Jul\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"10-Jun\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"C+\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"10-May\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"C\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"10-Mar\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"10-Aug\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"10-Apr\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"10-Oct\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"D+\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"7.5/10\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"53/100\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"9.25/10\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"D+\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"F\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"62/100\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"4.4/10\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"82/100\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"0.5/4\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"64/100\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"86/100\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"8.3/10\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"9.5/10\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"51/100\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"44/100\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"9.19/10\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"59/100\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"D-\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"D\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"0.5.5\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"3.5.5\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"6\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"0\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"9\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"7\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"470\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"3.5\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"2.75\"].index, inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {'review_score': float\n",
    "               }\n",
    "  \n",
    "df = df.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {'review_score': int\n",
    "               }\n",
    "  \n",
    "df = df.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     85986\n",
      "4     85912\n",
      "2     70854\n",
      "1     24999\n",
      "5     20769\n",
      "0      1732\n",
      "8         2\n",
      "14        1\n",
      "9         1\n",
      "24        1\n",
      "6         1\n",
      "45        1\n",
      "Name: review_score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "temp = df['review_score'].value_counts()\n",
    "with pd.option_context('display.max_rows',None):\n",
    "    print(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['review_score']==\"0\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"8\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"24\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"6\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"45\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"14\"].index, inplace = True)\n",
    "df.drop(df[df['review_score']==\"9\"].index, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3     85986\n",
      "4     85912\n",
      "2     70854\n",
      "1     24999\n",
      "5     20769\n",
      "0      1732\n",
      "8         2\n",
      "14        1\n",
      "9         1\n",
      "24        1\n",
      "6         1\n",
      "45        1\n",
      "Name: review_score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "temp_1 = df['review_score'].value_counts()\n",
    "with pd.option_context('display.max_rows',None):\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHOD FOR CLEANING THE REVIEW CONTENT\n",
    "def text_clean(message):\n",
    "  '''\n",
    "  message = \"#'This', is $string #with punction, <br /> @'html_tag' and actual message also!\"\n",
    "\n",
    "  return 'string punction html_tag actual message also'\n",
    "  '''\n",
    "\n",
    "  html_tag = '<br />'\n",
    "  message = message.replace(html_tag,'')  # remove html tag\n",
    "  message = re.sub(r'[^\\w\\s]', '', message)   # remove punctiation\n",
    "  message = message.lower()\n",
    "  message = [word for word in message.split() if word not in stopwords.words('english')]\n",
    "  message = ' '.join(message)\n",
    "\n",
    "  return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string punction html_tag actual message also'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = \"#'This', is $string #with punction, <br /> @'html_tag' and actual message also!\"\n",
    "text_clean(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_content'] = df['review_content'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher_name</th>\n",
       "      <th>review_type</th>\n",
       "      <th>review_score</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>The Age (Australia)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>crammed dragons setdestroying fights things ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>Daily Mirror (UK)</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>4</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>actionpacked fantasy adventure based rick rior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2</td>\n",
       "      <td>2/10/2010</td>\n",
       "      <td>chris columbus returns comfort zone mirthless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>False</td>\n",
       "      <td>CinemaBlend</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>3</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>best thing say chris columbuss adaptation hes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>True</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>2</td>\n",
       "      <td>2/11/2010</td>\n",
       "      <td>although standard allegorical bases mythicalqu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rotten_tomatoes_link  top_critic       publisher_name review_type  \\\n",
       "2            m/0814255        True  The Age (Australia)       Fresh   \n",
       "3            m/0814255       False    Daily Mirror (UK)       Fresh   \n",
       "4            m/0814255        True             Time Out      Rotten   \n",
       "5            m/0814255       False          CinemaBlend       Fresh   \n",
       "7            m/0814255        True       New York Times      Rotten   \n",
       "\n",
       "   review_score review_date                                     review_content  \n",
       "2             3   2/10/2010  crammed dragons setdestroying fights things ex...  \n",
       "3             4   2/10/2010  actionpacked fantasy adventure based rick rior...  \n",
       "4             2   2/10/2010  chris columbus returns comfort zone mirthless ...  \n",
       "5             3   2/11/2010  best thing say chris columbuss adaptation hes ...  \n",
       "7             2   2/11/2010  although standard allegorical bases mythicalqu...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2         crammed dragons setdestroying fights things ex...\n",
       "3         actionpacked fantasy adventure based rick rior...\n",
       "4         chris columbus returns comfort zone mirthless ...\n",
       "5         best thing say chris columbuss adaptation hes ...\n",
       "7         although standard allegorical bases mythicalqu...\n",
       "                                ...                        \n",
       "358245                                     movie revelation\n",
       "358246    rarity films allaction nofrills straightforwar...\n",
       "358247        spectacular war film powerful moral dimension\n",
       "358252    seen today startling indictment british imperi...\n",
       "358253    simple twoact story prelude war war former con...\n",
       "Name: review_content, Length: 290259, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF AND LINEAR SVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features = 20000,ngram_range = (1,5),analyzer='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['review_content'])\n",
    "Y = df['review_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((290259, 20000), (290259,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203181, 20000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=20, class_weight='balanced', dual=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(C = 20,class_weight = 'balanced',dual = False)\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.21      0.13       493\n",
      "           1       0.29      0.43      0.34      7566\n",
      "           2       0.49      0.47      0.48     21230\n",
      "           3       0.51      0.39      0.44     25899\n",
      "           4       0.53      0.48      0.50     25723\n",
      "           5       0.25      0.44      0.32      6166\n",
      "          45       1.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44     87078\n",
      "   macro avg       0.45      0.35      0.32     87078\n",
      "weighted avg       0.47      0.44      0.45     87078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred,zero_division = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'the movie was standard'\n",
    "x = text_clean(x)\n",
    "vec = tfidf.transform([x])\n",
    "clf.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\nishi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\n  File \"C:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\imp.py\", line 296, in find_module\n    raise ImportError(_ERR_MSG.format(name), name=name)\nImportError: No module named '_pywrap_tensorflow'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\nishi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"C:\\Users\\nishi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"C:\\Users\\nishi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nModuleNotFoundError: No module named '_pywrap_tensorflow'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:18\u001b[0m, in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=16'>17</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=17'>18</a>\u001b[0m     fp, pathname, description \u001b[39m=\u001b[39m imp\u001b[39m.\u001b[39;49mfind_module(\u001b[39m'\u001b[39;49m\u001b[39m_pywrap_tensorflow\u001b[39;49m\u001b[39m'\u001b[39;49m, [dirname(\u001b[39m__file__\u001b[39;49m)])\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=18'>19</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\imp.py:296\u001b[0m, in \u001b[0;36mfind_module\u001b[1;34m(name, path)\u001b[0m\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/imp.py?line=294'>295</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/imp.py?line=295'>296</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(_ERR_MSG\u001b[39m.\u001b[39mformat(name), name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/imp.py?line=297'>298</a>\u001b[0m encoding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named '_pywrap_tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py:66\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=62'>63</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=63'>64</a>\u001b[0m     \u001b[39m# TODO(keveman,mrry): Support dynamic op loading on platforms that do not\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=64'>65</a>\u001b[0m     \u001b[39m# use `dlopen()` for dynamic loading.\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=65'>66</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=66'>67</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _mod\n\u001b[1;32m---> <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=27'>28</a>\u001b[0m _pywrap_tensorflow \u001b[39m=\u001b[39m swig_import_helper()\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=28'>29</a>\u001b[0m \u001b[39mdel\u001b[39;00m swig_import_helper\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:20\u001b[0m, in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=18'>19</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=19'>20</a>\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39m_pywrap_tensorflow\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/pywrap_tensorflow.py?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _pywrap_tensorflow\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '_pywrap_tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nishi\\Documents\\data science\\SDP\\final_prediction.ipynb Cell 33'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000038?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m stopwords\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000038?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstem\u001b[39;00m \u001b[39mimport\u001b[39;00m WordNetLemmatizer\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000038?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtext\u001b[39;00m \u001b[39mimport\u001b[39;00m Tokenizer\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000038?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequence\u001b[39;00m \u001b[39mimport\u001b[39;00m pad_sequences\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000038?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Dropout\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/__init__.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/__init__.py?line=22'>23</a>\u001b[0m \u001b[39m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m---> <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/__init__.py?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/__init__.py?line=24'>25</a>\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/__init__.py?line=25'>26</a>\u001b[0m \n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/__init__.py?line=26'>27</a>\u001b[0m \u001b[39m# Lazily import the `tf.contrib` module. This avoids loading all of the\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/__init__.py?line=27'>28</a>\u001b[0m \u001b[39m# dependencies of `tf.contrib` at `import tensorflow` time.\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/__init__.py?line=28'>29</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_LazyContribLoader\u001b[39;00m(\u001b[39mobject\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py:72\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=66'>67</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=67'>68</a>\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[39m\\n\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=68'>69</a>\u001b[0m \u001b[39mSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\u001b[39m\u001b[39m\\n\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=69'>70</a>\u001b[0m \u001b[39mfor some common reasons and solutions.  Include the entire stack trace\u001b[39m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=70'>71</a>\u001b[0m \u001b[39mabove this error message when asking for help.\u001b[39m\u001b[39m\"\"\"\u001b[39m \u001b[39m%\u001b[39m traceback\u001b[39m.\u001b[39mformat_exc()\n\u001b[1;32m---> <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=71'>72</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=73'>74</a>\u001b[0m \u001b[39m# Protocol buffers\u001b[39;00m\n\u001b[0;32m     <a href='file:///~/AppData/Roaming/Python/Python39/site-packages/tensorflow/python/__init__.py?line=74'>75</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgraph_pb2\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\nishi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\n  File \"C:\\Users\\nishi\\AppData\\Local\\Programs\\Python\\Python39\\lib\\imp.py\", line 296, in find_module\n    raise ImportError(_ERR_MSG.format(name), name=name)\nImportError: No module named '_pywrap_tensorflow'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\nishi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"C:\\Users\\nishi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"C:\\Users\\nishi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\n    import _pywrap_tensorflow\nModuleNotFoundError: No module named '_pywrap_tensorflow'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "#import plotly.graph_objects as go\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "#import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import GlobalAvgPool1D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nishi\\Documents\\data science\\SDP\\final_prediction.ipynb Cell 34'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000036?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenization\u001b[39m(inputs):  \u001b[39m# Ref.1\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000036?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m word_tokenize(inputs)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000036?line=4'>5</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtext_tokenized\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mreview_content\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(tokenization)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000036?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mtext_tokenized\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\series.py:4430\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4319'>4320</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4320'>4321</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4321'>4322</a>\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4324'>4325</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4325'>4326</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4326'>4327</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4327'>4328</a>\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4328'>4329</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4427'>4428</a>\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4428'>4429</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/series.py?line=4429'>4430</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1077'>1078</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1078'>1079</a>\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1079'>1080</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1081'>1082</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1130'>1131</a>\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1131'>1132</a>\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1132'>1133</a>\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1133'>1134</a>\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1134'>1135</a>\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1135'>1136</a>\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1136'>1137</a>\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1137'>1138</a>\u001b[0m             values,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1138'>1139</a>\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1139'>1140</a>\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1140'>1141</a>\u001b[0m         )\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1142'>1143</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1143'>1144</a>\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1144'>1145</a>\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   <a href='file:///~/AppData/Local/Programs/Python/Python39/lib/site-packages/pandas/core/apply.py?line=1145'>1146</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nishi\\Documents\\data science\\SDP\\final_prediction.ipynb Cell 34'\u001b[0m in \u001b[0;36mtokenization\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000036?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenization\u001b[39m(inputs):  \u001b[39m# Ref.1\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nishi/Documents/data%20science/SDP/final_prediction.ipynb#ch0000036?line=1'>2</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m word_tokenize(inputs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "def tokenization(inputs):  # Ref.1\n",
    "    return word_tokenize(inputs)\n",
    "\n",
    "\n",
    "df['text_tokenized'] = df['review_content'].apply(tokenization)\n",
    "df['text_tokenized'].head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fd4a05da7d287d5d3aec574a45a230f4cc8e448b820a505235819aab6760413"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
